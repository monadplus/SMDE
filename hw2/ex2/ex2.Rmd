---
title: "Exercise 2. Obtain an expression to simulate new data"
author: "Arnau Abella"
date: "21/05/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lmtest)
library(FactoMineR)

dataset <- read.csv("/home/arnau/MIRI/SMDE/hw2/ex1/dataset.csv",header=TRUE,sep=",")
answer <- which(colnames(dataset) == "answer")
```

Image that you don't know anything regarding this dataset. You need to explore it because you want to define a model to obtain new data for your DOE (you want to detect the possible relations and the interactions between the factors, or maybe you want to test alternatives or predict future scenarios).

1. Explore the possible relations of all the factors and answer variable, you can use any technique developed during the course.

2. Describe what you find on this analysis and, explain if it is coherent with the knowledge you have from the data.

3. Propose an expression (as an example using a LRM) to understand the relations between the data. What are the factors that affects the answer?

In order to answer these three questions we are going to use the following techniques:

- Multiple Linear Regression Model
- Principal Component Analysis

## Multiple Linear Regression Model

Let's start by applying a *multiple linear regression model* to the generated dataset from the first exercise:

```{r}
reg_model1<-lm(answer~., data=dataset)
summary(reg_model1)
```

The implementation of `lm` is clever enough to detect that the factors f6-f10 are a linear combination of the factors f1-5.

We can analyze them separately. As expected, only factor 6 and factor 9 have a linear relation with the answer.

```{r}
reg_model2<-lm(answer~factor6+factor7+factor8+factor9+factor10, data=dataset)
summary(reg_model2)
```

The expression to compute the **answer** is the following $Ans = +0.005562 + 1.032*f_1 + 0.988*f_2 + 0.988*f_4 + 4.94*f_5$ which is a very good approximation of the one used to produce this random variables.

```{r}
reg_model3<-lm(answer~factor1+factor2+factor3+factor4+factor5, data=dataset)
summary(reg_model3)
```

## Testing Regression Assumptions

```{r}
### 1. Normality of the Error Term
# Using QQ plot
qqnorm(residuals(reg_model3))
# Using Histogram
hist(residuals(reg_model3))
#Shapiro Wilks Test
shapiro.test(residuals(reg_model3))
# H_0 is accepted: the error term does follows a Normal distribution (p > 0.05)

### 2. Homogenity of Variance ###
# Residual Analysis #
plot(residuals(reg_model3))
##Breusch Pagan Test
bptest(reg_model3)
# H_0 is accepted (p>0.05): the homogenity of variances is provided.

### 3. The independence of errors ### 
dwtest(reg_model3, alternative = "two.sided")
# There is not an autocorrelated in the data set (p>0.05).
# The errors/observations are independent.
```

\newpage

## Principal Component Analysis

Let's use **Principal Component Analysis** technique to analyze the dataset and its factors and extract an expression to predict an answer:

```{r, fig.height=3, fig.fullwidth=TRUE}
pca_ds<-PCA(dataset[,-answer]) # Remove the dependent variable score.
```

```{r}
pca_ds$eig # cumulative percentage of variance > 75%
plot(pca_ds$eig[,1], type="o", main="Scree Plot")
```

As you may see, the factors that are involved in the answer have the same direction in the plane. On the other hand, the ones that are not related with the answer, have another direction.

In order to extract an expression to predict the answer variable we are going to use a **principal component regression**:

```{r}
### Principal Component Regression
dataset$PC1<-pca_ds$ind$coord[,1]
dataset$PC2<-pca_ds$ind$coord[,2]
dataset$PC3<-pca_ds$ind$coord[,3]
reg_pc<-lm(answer~PC1 + PC2 + PC3, data=dataset)
summary(reg_pc)
```

This expression can be used to predict the answer variable.

## Testing PCA Assumptions

```{r}
#1. Normality
#Shapiro Wilks Test
shapiro.test(residuals(reg_pc))
# The error term does follow a Normal distribution. (p>0.05)

### 2. Homogenity of Variance ###
# Residual Analysis #
plot(residuals(reg_pc))
##Breusch Pagan Test
bptest(reg_pc)
# H0 is accepted (p>0.05).
# The homogenity of variances is provided.

### 3. The independence of errors ### 
dwtest(reg_pc, alternative = "two.sided")
# There is not an autocorrelaiton in the data set (p>0.05).
# The errors/observations are independent.
```